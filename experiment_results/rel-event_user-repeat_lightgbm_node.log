Loading Database object from /home/dengmiao/.cache/relbench/rel-event/db...
Done in 3.67 seconds.
Embedding raw data in mini-batch:   0%|          | 0/16 [00:00<?, ?it/s]Embedding raw data in mini-batch: 100%|██████████| 16/16 [00:00<00:00, 161.20it/s]
Embedding raw data in mini-batch:   0%|          | 0/16 [00:00<?, ?it/s]Embedding raw data in mini-batch:   6%|▋         | 1/16 [00:00<00:10,  1.37it/s]Embedding raw data in mini-batch: 100%|██████████| 16/16 [00:00<00:00, 20.05it/s]
Embedding raw data in mini-batch:   0%|          | 0/2 [00:00<?, ?it/s]Embedding raw data in mini-batch: 100%|██████████| 2/2 [00:00<00:00, 404.54it/s]
Embedding raw data in mini-batch:   0%|          | 0/2 [00:00<?, ?it/s]Embedding raw data in mini-batch: 100%|██████████| 2/2 [00:00<00:00, 340.42it/s]
Embedding raw data in mini-batch:   0%|          | 0/1 [00:00<?, ?it/s]Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 253.25it/s]
Embedding raw data in mini-batch:   0%|          | 0/1 [00:00<?, ?it/s]Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 200.90it/s]
[I 2025-06-29 00:37:01,824] A new study created in memory with name: no-name-85152b25-2509-43d3-bcde-a0dc6a507f3e
[I 2025-06-29 00:37:02,291] Trial 0 finished with value: 0.6534002229654403 and parameters: {'max_depth': 3, 'learning_rate': 0.0021900718509438844, 'num_leaves': 34, 'subsample': 0.9716337064029169, 'colsample_bytree': 0.7012038806753678, 'lambda_l1': 0.2858880451434138, 'lambda_l2': 0.019711884949497254, 'min_data_in_leaf': 43}. Best is trial 0 with value: 0.6534002229654403.
[LightGBM] [Fatal] Reducing `min_data_in_leaf` with `feature_pre_filter=true` may cause unexpected behaviour for features that were pre-filtered by the larger `min_data_in_leaf`.
You need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.
[LightGBM] [Fatal] Reducing `min_data_in_leaf` with `feature_pre_filter=true` may cause unexpected behaviour for features that were pre-filtered by the larger `min_data_in_leaf`.
You need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.
[I 2025-06-29 00:37:02,716] Trial 1 finished with value: 0.6265607580824972 and parameters: {'max_depth': 4, 'learning_rate': 0.0029925973877445427, 'num_leaves': 12, 'subsample': 0.5033925153595414, 'colsample_bytree': 0.3953407082209585, 'lambda_l1': 2.6280652765668, 'lambda_l2': 1.4240403768796893e-05, 'min_data_in_leaf': 35}. Best is trial 0 with value: 0.6534002229654403.
[I 2025-06-29 00:37:03,296] Trial 2 finished with value: 0.6360367892976588 and parameters: {'max_depth': 5, 'learning_rate': 0.049852376346030486, 'num_leaves': 899, 'subsample': 0.277250729302769, 'colsample_bytree': 0.9912768311546603, 'lambda_l1': 8.361813315093904, 'lambda_l2': 4.317359393873772e-08, 'min_data_in_leaf': 98}. Best is trial 0 with value: 0.6534002229654403.
[LightGBM] [Fatal] Reducing `min_data_in_leaf` with `feature_pre_filter=true` may cause unexpected behaviour for features that were pre-filtered by the larger `min_data_in_leaf`.
You need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.
[LightGBM] [Fatal] Reducing `min_data_in_leaf` with `feature_pre_filter=true` may cause unexpected behaviour for features that were pre-filtered by the larger `min_data_in_leaf`.
You need to set `feature_pre_filter=false` to dynamically change the `min_data_in_leaf`.
[I 2025-06-29 00:37:03,846] Trial 3 finished with value: 0.640746934225195 and parameters: {'max_depth': 7, 'learning_rate': 0.046570550034132734, 'num_leaves': 994, 'subsample': 0.4111766136842319, 'colsample_bytree': 0.07490303018918994, 'lambda_l1': 3.0837136649586446e-06, 'lambda_l2': 0.016781727633618508, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.6534002229654403.
[I 2025-06-29 00:37:04,103] Trial 4 finished with value: 0.6712095875139353 and parameters: {'max_depth': 3, 'learning_rate': 0.001997844509909686, 'num_leaves': 454, 'subsample': 0.4465430885811733, 'colsample_bytree': 0.7185977266775804, 'lambda_l1': 1.4479937005445566e-07, 'lambda_l2': 0.016398759884910456, 'min_data_in_leaf': 28}. Best is trial 4 with value: 0.6712095875139353.
[I 2025-06-29 00:37:04,310] Trial 5 finished with value: 0.6318561872909699 and parameters: {'max_depth': 7, 'learning_rate': 0.02240198349543858, 'num_leaves': 444, 'subsample': 0.44520323976812254, 'colsample_bytree': 0.11567073700811105, 'lambda_l1': 0.012062057737531075, 'lambda_l2': 0.00010167071819600798, 'min_data_in_leaf': 93}. Best is trial 4 with value: 0.6712095875139353.
[I 2025-06-29 00:37:04,862] Trial 6 finished with value: 0.626644370122631 and parameters: {'max_depth': 11, 'learning_rate': 0.0012094191384035096, 'num_leaves': 476, 'subsample': 0.4377121635345976, 'colsample_bytree': 0.34935132222198423, 'lambda_l1': 1.70699521638102, 'lambda_l2': 3.7067220073125685e-08, 'min_data_in_leaf': 21}. Best is trial 4 with value: 0.6712095875139353.
[I 2025-06-29 00:37:05,203] Trial 7 finished with value: 0.6472129319955406 and parameters: {'max_depth': 3, 'learning_rate': 0.060145890205788304, 'num_leaves': 604, 'subsample': 0.6327286338597974, 'colsample_bytree': 0.6719506482767942, 'lambda_l1': 3.0315859060968458e-06, 'lambda_l2': 1.160268238751734e-08, 'min_data_in_leaf': 82}. Best is trial 4 with value: 0.6712095875139353.
[I 2025-06-29 00:37:05,364] Trial 8 finished with value: 0.6512263099219622 and parameters: {'max_depth': 3, 'learning_rate': 0.020869877754066513, 'num_leaves': 87, 'subsample': 0.3032596379437044, 'colsample_bytree': 0.056701251485179946, 'lambda_l1': 2.7905105703066027, 'lambda_l2': 2.187497685156867e-06, 'min_data_in_leaf': 79}. Best is trial 4 with value: 0.6712095875139353.
[I 2025-06-29 00:37:05,808] Trial 9 finished with value: 0.6348104793756968 and parameters: {'max_depth': 11, 'learning_rate': 0.05091695113644551, 'num_leaves': 862, 'subsample': 0.6624139829976874, 'colsample_bytree': 0.19709540560604577, 'lambda_l1': 0.24132586809117043, 'lambda_l2': 4.052499814634302e-06, 'min_data_in_leaf': 54}. Best is trial 4 with value: 0.6712095875139353.
Train: {'accuracy': 0.5101509630400833, 'average_precision': 0.5912116421182566, 'f1': 0.0, 'roc_auc': 0.5973471827625844}
Val: {'accuracy': 0.5149253731343284, 'average_precision': 0.6323692805721941, 'f1': 0.0, 'roc_auc': 0.6712095875139353}
Test: {'accuracy': 0.5528455284552846, 'average_precision': 0.6207443999446052, 'f1': 0.0, 'roc_auc': 0.6917112299465241}
